{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP Classifier for the MNIST hand-written digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch, numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor()\n",
    "                              ])\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# choose the training and test datasets\n",
    "traindata = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "testdata = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(traindata)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "trainsampler = SubsetRandomSampler(train_idx)\n",
    "validsampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=batch_size,\n",
    "    sampler=trainsampler, num_workers=num_workers)\n",
    "validloader = torch.utils.data.DataLoader(traindata, batch_size=batch_size, \n",
    "    sampler=validsampler, num_workers=num_workers)\n",
    "testloader = torch.utils.data.DataLoader(testdata, batch_size=batch_size, \n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(256, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the untrained model\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.078471 \tValidation Loss: 0.118134\n",
      "Validation loss decreased (inf --> 0.118134).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.453979 \tValidation Loss: 0.078435\n",
      "Validation loss decreased (inf --> 0.078435).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.353694 \tValidation Loss: 0.066837\n",
      "Validation loss decreased (inf --> 0.066837).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.307861 \tValidation Loss: 0.059296\n",
      "Validation loss decreased (inf --> 0.059296).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.278787 \tValidation Loss: 0.054254\n",
      "Validation loss decreased (inf --> 0.054254).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.252654 \tValidation Loss: 0.049155\n",
      "Validation loss decreased (inf --> 0.049155).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.232030 \tValidation Loss: 0.045724\n",
      "Validation loss decreased (inf --> 0.045724).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.213158 \tValidation Loss: 0.042406\n",
      "Validation loss decreased (inf --> 0.042406).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.199347 \tValidation Loss: 0.039446\n",
      "Validation loss decreased (inf --> 0.039446).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.188022 \tValidation Loss: 0.037109\n",
      "Validation loss decreased (inf --> 0.037109).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.176498 \tValidation Loss: 0.034761\n",
      "Validation loss decreased (inf --> 0.034761).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.166214 \tValidation Loss: 0.033513\n",
      "Validation loss decreased (inf --> 0.033513).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.157389 \tValidation Loss: 0.031806\n",
      "Validation loss decreased (inf --> 0.031806).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.149314 \tValidation Loss: 0.030119\n",
      "Validation loss decreased (inf --> 0.030119).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.141133 \tValidation Loss: 0.028996\n",
      "Validation loss decreased (inf --> 0.028996).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.135682 \tValidation Loss: 0.027731\n",
      "Validation loss decreased (inf --> 0.027731).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.129871 \tValidation Loss: 0.026462\n",
      "Validation loss decreased (inf --> 0.026462).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.124381 \tValidation Loss: 0.026105\n",
      "Validation loss decreased (inf --> 0.026105).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.121559 \tValidation Loss: 0.025315\n",
      "Validation loss decreased (inf --> 0.025315).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.114818 \tValidation Loss: 0.024722\n",
      "Validation loss decreased (inf --> 0.024722).  Saving model ...\n",
      "Epoch: 21 \tTraining Loss: 0.111438 \tValidation Loss: 0.023659\n",
      "Validation loss decreased (inf --> 0.023659).  Saving model ...\n",
      "Epoch: 22 \tTraining Loss: 0.108309 \tValidation Loss: 0.023169\n",
      "Validation loss decreased (inf --> 0.023169).  Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 0.106284 \tValidation Loss: 0.022378\n",
      "Validation loss decreased (inf --> 0.022378).  Saving model ...\n",
      "Epoch: 24 \tTraining Loss: 0.101241 \tValidation Loss: 0.021843\n",
      "Validation loss decreased (inf --> 0.021843).  Saving model ...\n",
      "Epoch: 25 \tTraining Loss: 0.100636 \tValidation Loss: 0.021501\n",
      "Validation loss decreased (inf --> 0.021501).  Saving model ...\n",
      "Epoch: 26 \tTraining Loss: 0.095912 \tValidation Loss: 0.021190\n",
      "Validation loss decreased (inf --> 0.021190).  Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 0.094162 \tValidation Loss: 0.020281\n",
      "Validation loss decreased (inf --> 0.020281).  Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 0.091094 \tValidation Loss: 0.019978\n",
      "Validation loss decreased (inf --> 0.019978).  Saving model ...\n",
      "Epoch: 29 \tTraining Loss: 0.089101 \tValidation Loss: 0.019926\n",
      "Validation loss decreased (inf --> 0.019926).  Saving model ...\n",
      "Epoch: 30 \tTraining Loss: 0.085949 \tValidation Loss: 0.020133\n",
      "Epoch: 31 \tTraining Loss: 0.083892 \tValidation Loss: 0.019324\n",
      "Validation loss decreased (inf --> 0.019324).  Saving model ...\n",
      "Epoch: 32 \tTraining Loss: 0.083282 \tValidation Loss: 0.019096\n",
      "Validation loss decreased (inf --> 0.019096).  Saving model ...\n",
      "Epoch: 33 \tTraining Loss: 0.080106 \tValidation Loss: 0.018553\n",
      "Validation loss decreased (inf --> 0.018553).  Saving model ...\n",
      "Epoch: 34 \tTraining Loss: 0.078090 \tValidation Loss: 0.018551\n",
      "Validation loss decreased (inf --> 0.018551).  Saving model ...\n",
      "Epoch: 35 \tTraining Loss: 0.076477 \tValidation Loss: 0.017868\n",
      "Validation loss decreased (inf --> 0.017868).  Saving model ...\n",
      "Epoch: 36 \tTraining Loss: 0.074725 \tValidation Loss: 0.018074\n",
      "Epoch: 37 \tTraining Loss: 0.072915 \tValidation Loss: 0.017439\n",
      "Validation loss decreased (inf --> 0.017439).  Saving model ...\n",
      "Epoch: 38 \tTraining Loss: 0.071658 \tValidation Loss: 0.017214\n",
      "Validation loss decreased (inf --> 0.017214).  Saving model ...\n",
      "Epoch: 39 \tTraining Loss: 0.070521 \tValidation Loss: 0.017040\n",
      "Validation loss decreased (inf --> 0.017040).  Saving model ...\n",
      "Epoch: 40 \tTraining Loss: 0.069488 \tValidation Loss: 0.017019\n",
      "Validation loss decreased (inf --> 0.017019).  Saving model ...\n",
      "Epoch: 41 \tTraining Loss: 0.066802 \tValidation Loss: 0.016610\n",
      "Validation loss decreased (inf --> 0.016610).  Saving model ...\n",
      "Epoch: 42 \tTraining Loss: 0.064246 \tValidation Loss: 0.016405\n",
      "Validation loss decreased (inf --> 0.016405).  Saving model ...\n",
      "Epoch: 43 \tTraining Loss: 0.065618 \tValidation Loss: 0.016627\n",
      "Epoch: 44 \tTraining Loss: 0.062233 \tValidation Loss: 0.016456\n",
      "Epoch: 45 \tTraining Loss: 0.060622 \tValidation Loss: 0.016202\n",
      "Validation loss decreased (inf --> 0.016202).  Saving model ...\n",
      "Epoch: 46 \tTraining Loss: 0.058839 \tValidation Loss: 0.015970\n",
      "Validation loss decreased (inf --> 0.015970).  Saving model ...\n",
      "Epoch: 47 \tTraining Loss: 0.059570 \tValidation Loss: 0.016047\n",
      "Epoch: 48 \tTraining Loss: 0.058364 \tValidation Loss: 0.015692\n",
      "Validation loss decreased (inf --> 0.015692).  Saving model ...\n",
      "Epoch: 49 \tTraining Loss: 0.055195 \tValidation Loss: 0.015437\n",
      "Validation loss decreased (inf --> 0.015437).  Saving model ...\n",
      "Epoch: 50 \tTraining Loss: 0.055619 \tValidation Loss: 0.015577\n"
     ]
    }
   ],
   "source": [
    "# Train the model for 10 epochs\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 50\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "validloss_min = np.Inf # set initial \"min\" to infinity\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    trainloss = 0.0\n",
    "    validloss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train() # prep model for training\n",
    "    for data, target in trainloader:\n",
    "        data = data.view(-1, 28 * 28)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        trainloss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval() # prep model for evaluation\n",
    "    for data, target in validloader:\n",
    "        data = data.view(-1, 28 * 28)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update running validation loss \n",
    "        validloss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    # calculate average loss over an epoch\n",
    "    trainloss = trainloss/len(trainloader.dataset)\n",
    "    validloss = validloss/len(validloader.dataset)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        trainloss,\n",
    "        validloss\n",
    "        ))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if validloss <= validloss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        validloss))\n",
    "        torch.save(model.state_dict(), 'model.pth')\n",
    "        validloss_min = validloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.074377\n",
      "\n",
      "Test Accuracy of     0: 98% (970/980)\n",
      "Test Accuracy of     1: 99% (1125/1135)\n",
      "Test Accuracy of     2: 97% (1009/1032)\n",
      "Test Accuracy of     3: 98% (990/1010)\n",
      "Test Accuracy of     4: 97% (960/982)\n",
      "Test Accuracy of     5: 96% (862/892)\n",
      "Test Accuracy of     6: 97% (937/958)\n",
      "Test Accuracy of     7: 97% (1000/1028)\n",
      "Test Accuracy of     8: 96% (944/974)\n",
      "Test Accuracy of     9: 96% (974/1009)\n",
      "\n",
      "Test Accuracy (Overall): 97% (9771/10000)\n"
     ]
    }
   ],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "testloss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval() # prep model for evaluation\n",
    "\n",
    "for data, target in testloader:\n",
    "    data = data.view(-1, 28 * 28)\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    testloss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# calculate and print avg test loss\n",
    "testloss = testloss/len(testloader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(testloss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model after training\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
